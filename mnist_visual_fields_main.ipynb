{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJdPAuFqKDVc"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wNKXU3BGuWq"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "import numpy as np\n",
        "from typing import Tuple, List\n",
        "from attr import define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if tf.config.list_physical_devices('GPU'):\n",
        "  print(\"TensorFlow **IS** using the GPU\")\n",
        "else:\n",
        "  print(\"TensorFlow **IS NOT** using the GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LngGn84xMeV6"
      },
      "source": [
        "Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9iFws82Mdmi"
      },
      "outputs": [],
      "source": [
        "def normalize_ndarray(array: np.ndarray) -> np.ndarray:\n",
        "\n",
        "    max = np.max(array)\n",
        "    min = np.min(array)\n",
        "\n",
        "    if (max - min) == 0:\n",
        "        return array\n",
        "    else:\n",
        "        return (array - min) / (max - min)\n",
        "\n",
        "\n",
        "def show_dataset(\n",
        "    x_data_left: np.array, x_data_right: np.array, y_data: np.array, num_images: int\n",
        ") -> None:\n",
        "    fig1, ax = plt.subplots(num_images, 2, figsize=(2.4, num_images * 1.2))\n",
        "    for i in range(num_images):\n",
        "        ax[i, 0].imshow(x_data_left[i], cmap=\"binary\", vmax=1)\n",
        "        ax[i, 1].imshow(x_data_right[i], cmap=\"binary\", vmax=1)\n",
        "\n",
        "        ax[i, 1].text(45, 18, f\"{y_data[i]}\", fontsize=20)\n",
        "\n",
        "        ax[i, 0].set_xticks([])\n",
        "        ax[i, 0].set_yticks([])\n",
        "        ax[i, 1].set_xticks([])\n",
        "        ax[i, 1].set_yticks([])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_single_digit(x_data, y_data, index, print_index: bool):\n",
        "    image = x_data[index]\n",
        "    digit = y_data[index]\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(3, 3))\n",
        "\n",
        "    ax1.imshow(image, cmap=\"binary\", vmax=1)\n",
        "    ax1.set_title(\"Image\")\n",
        "    ax1.set_aspect(\"equal\")\n",
        "    ax1.set_xticks([])\n",
        "    ax1.set_yticks([])\n",
        "\n",
        "    if not print_index:\n",
        "        ax2.set_title(\"Digit\")\n",
        "        ax2.text(0.4, 0.5, f\"{digit}\", fontsize=20)\n",
        "    else:\n",
        "        ax2.set_title(\"Index\")\n",
        "        ax2.text(0.4, 0.5, f\"{index}\", fontsize=20)\n",
        "\n",
        "    ax2.set_aspect(\"equal\")\n",
        "    ax2.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_double_digit(x_data_left, x_data_right, y_data, index):\n",
        "    image_left = x_data_left[index]\n",
        "    image_right = x_data_right[index]\n",
        "    digit = y_data[index]\n",
        "\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(3, 3))\n",
        "\n",
        "    ax1.imshow(image_left, cmap=\"binary\", vmax=1)\n",
        "    ax1.set_title(\"Image\")\n",
        "    ax1.set_aspect(\"equal\")\n",
        "    ax1.set_xticks([])\n",
        "    ax1.set_yticks([])\n",
        "\n",
        "    ax2.imshow(image_right, cmap=\"binary\", vmax=1)\n",
        "    ax2.set_title(\"Image\")\n",
        "    ax2.set_aspect(\"equal\")\n",
        "    ax2.set_xticks([])\n",
        "    ax2.set_yticks([])\n",
        "\n",
        "    ax3.set_title(\"Digit\")\n",
        "    ax3.text(0.4, 0.5, f\"{digit}\", fontsize=20)\n",
        "    ax3.set_aspect(\"equal\")\n",
        "    ax3.axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdTuPFiVReAK"
      },
      "source": [
        "Generating dataset functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Gowf75R8Rf6L"
      },
      "outputs": [],
      "source": [
        "def shuffle_visual_field_dataset(\n",
        "    x_data: np.array, y_data: np.array\n",
        ") -> Tuple[np.array, np.array]:\n",
        "    # shuffles dataset comprised of two arrays\n",
        "\n",
        "    n = len(y_data)\n",
        "    unique_indices = np.random.permutation(\n",
        "        n\n",
        "    )  # generates random permutation of list in range(0, n)\n",
        "    x_data = x_data[unique_indices]\n",
        "    y_data = y_data[unique_indices]\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "\n",
        "def shuffle_two_visual_fields_dataset(\n",
        "    x_data_left: np.array, x_data_right: np.array, y_data: np.array\n",
        ") -> Tuple[np.array, np.array, np.array]:\n",
        "    # Shuffles dataset comprised of three arrays\n",
        "\n",
        "    n = len(y_data)\n",
        "    unique_indices = np.random.permutation(\n",
        "        n\n",
        "    )  # generates random permutation of list in range(0, n)\n",
        "    x_data_left = x_data_left[unique_indices]\n",
        "    x_data_right = x_data_right[unique_indices]\n",
        "    y_data = y_data[unique_indices]\n",
        "\n",
        "    return x_data_left, x_data_right, y_data\n",
        "\n",
        "\n",
        "def shuffle_and_double_dataset(\n",
        "    x_data: np.array, y_data: np.array\n",
        ") -> Tuple[np.array, np.array]:\n",
        "    x_data1, y_data1 = shuffle_visual_field_dataset(x_data, y_data)\n",
        "    x_data2, y_data2 = shuffle_visual_field_dataset(x_data, y_data)\n",
        "\n",
        "    x_data_concatenated = np.concatenate((x_data1, x_data2))\n",
        "    y_data_concatenated = np.concatenate((y_data1, y_data2))\n",
        "\n",
        "    return x_data_concatenated, y_data_concatenated\n",
        "\n",
        "\n",
        "def build_visual_field_data(\n",
        "    x_data: np.array, y_data: np.array, n: float\n",
        ") -> Tuple[np.array, np.array]:\n",
        "    \"\"\"\n",
        "    Builds the dataset for a single visual field, choosing random values from the input.\n",
        "\n",
        "    Input:\n",
        "    x_data: np.array(np.ndarray): array of two-dimensional arrays corresponding to the pixel values of digits of the MNIST dataset.\n",
        "    y_data: np.array(int): corresponding value of the digit represented by x_data.\n",
        "    n: float: size of the final dataset\n",
        "\n",
        "    Output:\n",
        "    x_data_right: np.array(np.ndarray): array of two-dimensional arrays corresponding to the pixel values of digits of the MNIST dataset.\n",
        "    y_data: np.array(int): corresponding value of the digit of the visual field.\n",
        "    \"\"\"\n",
        "\n",
        "    original_size = len(y_data)\n",
        "    random_indices = np.random.choice(np.arange(0, original_size), n)\n",
        "    x_data_visual_field = x_data[random_indices]\n",
        "    y_data_visual_field = y_data[random_indices]\n",
        "\n",
        "    return x_data_visual_field, y_data_visual_field\n",
        "\n",
        "\n",
        "def build_double_visual_fields_dataset(\n",
        "    x_data: np.array,\n",
        "    y_data: np.array,\n",
        "    final_size: float = 4,\n",
        "    proportion_cs: float = 0.5,\n",
        "    proportion_left: float = 0.5,\n",
        "    full_attention_value: float = 1,\n",
        "    reduced_attention_value: float = 0.5,\n",
        "    ss_attention_value: float = 0.5,\n",
        ") -> Tuple[np.array, np.array, np.array]:\n",
        "    \"\"\"\n",
        "    Builds an entire double visual fields dataset, comprised of two visual fields, left and right, and an array of the corresponding answer value for both visual fields.\n",
        "\n",
        "    Input:\n",
        "    x_data: np.array(np.ndarray): array of two-dimensional arrays corresponding to the pixel values of digits of the MNIST dataset.\n",
        "    y_data: np.array(int): corresponding value of the digit represented by x_data.\n",
        "    final_size: float: how many times the final dataset is bigger than the input data. Default is 4.\n",
        "    proportion_cs: float: proportion of entries in the final dataset that have CS over SS. Default is 0.5.\n",
        "    proportion_left: float: proportion of entries in the final dataset that have attention on the left visual field. Default is 0.5.\n",
        "    full_attention_value: float: value of the full attention in CS. Default is 1.\n",
        "    reduced_attention_value: float: value of the reduced attention in CS. Default is 0.5.\n",
        "    ss_attention_value: float: value of the attention for SS. Default is 0.5.\n",
        "\n",
        "    Output:\n",
        "    x_data_left: np.array(np.ndarray): array of two-dimensional arrays corresponding to the pixel values of digits of the MNIST dataset with a determined attention.\n",
        "    x_data_right: np.array(np.ndarray): array of two-dimensional arrays corresponding to the pixel values of digits of the MNIST dataset with a determined attention.\n",
        "    y_data: np.array(int): corresponding value of the digit that has most attention considering both visual fields.\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(y_data) * final_size\n",
        "    x_data_left, y_data_left = build_visual_field_data(x_data, y_data, n)\n",
        "    x_data_right, y_data_right = build_visual_field_data(x_data, y_data, n)\n",
        "\n",
        "    y_data_final = np.zeros(n, dtype=int)\n",
        "    for i in range(n):\n",
        "        data_with_cs = np.random.choice(\n",
        "            [False, True], p=[1 - proportion_cs, proportion_cs]\n",
        "        )\n",
        "        data_with_left_attention = np.random.choice(\n",
        "            [False, True], p=[1 - proportion_left, proportion_left]\n",
        "        )\n",
        "\n",
        "        # determines value of attention if dataset entry is CS or SS\n",
        "        if data_with_cs:\n",
        "            attention = full_attention_value\n",
        "            no_attention = reduced_attention_value\n",
        "        else:\n",
        "            attention = ss_attention_value\n",
        "            no_attention = 0\n",
        "\n",
        "        # determines which visual field has attention\n",
        "        if data_with_left_attention:\n",
        "            x_data_left[i] *= attention\n",
        "            x_data_right[i] *= no_attention\n",
        "            y_data_final[i] = y_data_left[i]\n",
        "        else:\n",
        "            x_data_left[i] *= no_attention\n",
        "            x_data_right[i] *= attention\n",
        "            y_data_final[i] = y_data_right[i]\n",
        "\n",
        "    return x_data_left, x_data_right, y_data_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QcrFX-ZKPLJ"
      },
      "source": [
        "Importing dataset and normalizing input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NoeV7ONKIaO",
        "outputId": "a2415cb9-a248-4cd1-d308-a7eccbe5830b"
      },
      "outputs": [],
      "source": [
        "mnist_dataset = keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist_dataset.load_data()\n",
        "x_train = normalize_ndarray(x_train)\n",
        "x_test = normalize_ndarray(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckbuOoWUXDhq"
      },
      "source": [
        "Building training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOUxWDbKKCai"
      },
      "outputs": [],
      "source": [
        "x_train_left, x_train_right, y_train_final = build_double_visual_fields_dataset(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    final_size=4,\n",
        "    proportion_cs=0.5,\n",
        "    proportion_left=0.5,\n",
        "    full_attention_value=1,\n",
        "    reduced_attention_value=0.5,\n",
        "    ss_attention_value=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8gGTdb9X842"
      },
      "source": [
        "Showing training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "collapsed": true,
        "id": "1vxEzCZAYBSj",
        "outputId": "9bb42de4-e298-4486-8838-ab857e41f737"
      },
      "outputs": [],
      "source": [
        "show_dataset(x_train_left, x_train_right, y_train_final, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45nm6T8SeyZN"
      },
      "source": [
        "Building testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4oz4CJze01X"
      },
      "outputs": [],
      "source": [
        "x_test_left, x_test_right, y_test_final = build_double_visual_fields_dataset(\n",
        "    x_test,\n",
        "    y_test,\n",
        "    final_size=1,\n",
        "    proportion_cs=0.5,\n",
        "    proportion_left=0.5,\n",
        "    full_attention_value=1,\n",
        "    reduced_attention_value=0.5,\n",
        "    ss_attention_value=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-osk16rCfuX_"
      },
      "source": [
        "Showing testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "collapsed": true,
        "id": "ep873be-fxmQ",
        "outputId": "a0135e78-0332-46ee-d357-c94a3626e763"
      },
      "outputs": [],
      "source": [
        "show_dataset(x_test_left, x_test_right, y_test_final, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlPMetPM41tm"
      },
      "source": [
        "**Visualizing Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABhrN7amSA4-"
      },
      "source": [
        "Plotting Neural Network dataclasses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP1vZCccSAEp"
      },
      "outputs": [],
      "source": [
        "@define\n",
        "class Position:\n",
        "    \"\"\"\n",
        "    Class representing a position with two coordinates\n",
        "    \"\"\"\n",
        "\n",
        "    x: float\n",
        "    y: float\n",
        "\n",
        "    def copy(self):\n",
        "        return Position(self.x, self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Position({self.x}, {self.y})\"\n",
        "\n",
        "\n",
        "@define\n",
        "class Neuron:\n",
        "    \"\"\"\n",
        "    Class representing a neuron in the Neural Network plot\n",
        "    \"\"\"\n",
        "\n",
        "    activation: float\n",
        "    position: Position\n",
        "    radius: float\n",
        "\n",
        "\n",
        "@define\n",
        "class Layer:\n",
        "    \"\"\"\n",
        "    Class representing a layer in the Neural Network plot\n",
        "    \"\"\"\n",
        "\n",
        "    model: keras.layers\n",
        "    activations: List[float] | None = None\n",
        "    position: Position | None = None\n",
        "    neurons: List[Neuron] | None = None\n",
        "    num_neurons: int | None = None\n",
        "\n",
        "    def __attrs_post_init__(self):\n",
        "        self.neurons = ([])  # This is needed to solve bug where list is not empty at start\n",
        "        self.num_neurons = self.model.output_shape[-1]\n",
        "\n",
        "    def is_output_layer(self):\n",
        "        return not bool(self.model._outbound_nodes)\n",
        "\n",
        "    def set_y_position(self, y_position):\n",
        "        self.position.y = y_position"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa60X1SZPEDm"
      },
      "source": [
        "Auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF_-HBr9PK2f"
      },
      "outputs": [],
      "source": [
        "def get_index_of_digit(y_data, digit):\n",
        "    \"\"\"\n",
        "    Return index of first occurance of digit in the dataset, if digit is not found, returns -1\n",
        "    \"\"\"\n",
        "    n = len(y_data)\n",
        "    index = 0\n",
        "    while y_data[index] != digit and index < n - 1:\n",
        "        index += 1\n",
        "\n",
        "    return index if y_data[index] == digit else -1\n",
        "\n",
        "\n",
        "def get_single_visual_field_digit(x_data, y_data, digit):\n",
        "    \"\"\"\n",
        "    Returns the first instance of the digit in the Single Visual Field dataset\n",
        "    \"\"\"\n",
        "    index = get_index_of_digit(y_data, digit)\n",
        "\n",
        "    return np.array([x_data[index]])\n",
        "\n",
        "\n",
        "def get_double_visual_field_digit(x_data_left, x_data_right, y_data, digit):\n",
        "    \"\"\"\n",
        "    Returns the first instance of the digit in the Double Visual Field dataset\n",
        "    \"\"\"\n",
        "    index = get_index_of_digit(y_data, digit)\n",
        "    if index == -1:\n",
        "        print(\"Error! Digit wasn't found!\")\n",
        "\n",
        "    return np.array([x_data_left[index]]), np.array([x_data_right[index]])\n",
        "\n",
        "\n",
        "def get_activations_single_visual_field(model, input_digit, x_data, y_data):\n",
        "    \"\"\"\n",
        "    Generates the individual neuron activation values for a prediction with a single visual field Neural Network\n",
        "    \"\"\"\n",
        "\n",
        "    # Creating intermediate models\n",
        "    intermediate_layer_models = [\n",
        "        keras.models.Model(\n",
        "            inputs=model.input, outputs=layer.output\n",
        "        )\n",
        "        for layer in model.layers\n",
        "    ]\n",
        "\n",
        "    # Getting activations\n",
        "    input_data = get_single_visual_field_digit(x_train, y_train, input_digit)\n",
        "    activations = [\n",
        "        intermediate_layer_model(input_data)[0]\n",
        "        for intermediate_layer_model in intermediate_layer_models\n",
        "    ]  # Predict result is returned inside a list, hence we get the first element of that list\n",
        "\n",
        "    return activations\n",
        "\n",
        "def get_activations_double_visual_field(\n",
        "    model,\n",
        "    x_data=None,\n",
        "    left_vf_digit: Tuple[int, float] = None,\n",
        "    right_vf_digit: Tuple[int, float] = None,\n",
        "    x_data_left=None,\n",
        "    x_data_right=None,\n",
        "    input_digit=None,\n",
        "    y_data=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates the individual neuron activation values for a prediction with a double visual field Neural Network\n",
        "    \"\"\"\n",
        "\n",
        "    # Creating intermediate models\n",
        "    intermediate_layer_models = [\n",
        "        keras.models.Model(\n",
        "            inputs=model.input, outputs=layer.output\n",
        "        )\n",
        "        for layer in model.layers\n",
        "    ]\n",
        "\n",
        "    # Getting activations\n",
        "    if left_vf_digit is None:\n",
        "        input_data_left, input_data_right = get_double_visual_field_digit(\n",
        "            x_data_left, x_data_right, y_data, input_digit\n",
        "        )\n",
        "    else:\n",
        "        left_idx, left_attention = left_vf_digit\n",
        "        input_data_left = np.array([x_data[left_idx]]) * left_attention\n",
        "        right_idx, right_attention = right_vf_digit\n",
        "        input_data_right = np.array([x_data[right_idx]]) * right_attention\n",
        "    activations = [\n",
        "        intermediate_layer_model([input_data_left, input_data_right])[0]\n",
        "        for intermediate_layer_model in intermediate_layer_models\n",
        "    ]   # Model result is returned inside a list, hence we get the first element of that list\n",
        "\n",
        "    return activations\n",
        "\n",
        "\n",
        "def get_image(neural_activation):\n",
        "    \"\"\"\n",
        "    Transforms the activity of the neurons of a Neural Network into a 2D matrix that can be seen as an image with plt.imshow\n",
        "    \"\"\"\n",
        "    num_neurons = len(neural_activation)\n",
        "    num_rows = int(np.sqrt(num_neurons))\n",
        "    num_cols = int(np.ceil(num_neurons / num_rows))\n",
        "\n",
        "    return np.array(neural_activation).reshape(num_rows, num_cols)\n",
        "\n",
        "\n",
        "def generate_image_annotation_box(\n",
        "    image, position, size, border_size=1, border_color=\"black\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates the AB of the image to be positioned in the figure\n",
        "    \"\"\"\n",
        "    img = OffsetImage(image, zoom=size)\n",
        "    ab = AnnotationBbox(img, (position.x, position.y), frameon=False, pad=0)\n",
        "\n",
        "    return ab\n",
        "\n",
        "\n",
        "def generate_image_annotation_box_grayscale(\n",
        "    image, position, size, border_width=1, border_color=\"black\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates the AnnotationBbox of the grayscale image with a border to be positioned in the figure\n",
        "    \"\"\"\n",
        "\n",
        "    img = OffsetImage(\n",
        "        image, zoom=size, cmap=\"binary\", norm=plt.Normalize(vmin=0, vmax=1)\n",
        "    )\n",
        "    ab = AnnotationBbox(\n",
        "        img,\n",
        "        (position.x, position.y),\n",
        "        frameon=True,\n",
        "        pad=0,\n",
        "        bboxprops=dict(\n",
        "            edgecolor=border_color, linewidth=border_width, boxstyle=\"square,pad=0.1\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return ab\n",
        "\n",
        "\n",
        "def get_number_of_neurons_in_layer(layer):\n",
        "    \"\"\"\n",
        "    Returns the number of neurons present in a layer of a Neural Network\n",
        "    \"\"\"\n",
        "    return layer.output_shape[-1]\n",
        "\n",
        "\n",
        "def get_digit_from_y_spacing(total_position_plotted, y_spacing):\n",
        "    \"\"\"\n",
        "    Returns the digit an output neuron represents based on how many neurons have been plotted\n",
        "    \"\"\"\n",
        "    return np.ceil(total_position_plotted / y_spacing)\n",
        "\n",
        "\n",
        "def calculate_image_size(number_neurons):\n",
        "    \"\"\"\n",
        "    Computes size of image based on the number of neurons\n",
        "    \"\"\"\n",
        "    # Determined in tests\n",
        "    a = -5 / 1536\n",
        "    b = 533 / 96\n",
        "    return number_neurons * a + b\n",
        "\n",
        "\n",
        "def compute_sizes(top):\n",
        "    bottom = 1 - top\n",
        "    return top, bottom, bottom, top  # top, bottom, left, right\n",
        "\n",
        "\n",
        "def display_n_digits(x_data, y_data, digit: int, n: int):\n",
        "    size = len(y_data)\n",
        "    idx = 0\n",
        "    digits_found = 0\n",
        "    idx_last_digit = 0\n",
        "    while idx < size and digits_found < n:\n",
        "        if y_data[idx] == digit:\n",
        "            digits_found += 1\n",
        "            idx_last_digit = idx\n",
        "            show_single_digit(x_data, y_data, idx, print_index=True)\n",
        "        idx += 1\n",
        "\n",
        "def generate_output_models(model):\n",
        "  # Generate not trainable copy of model\n",
        "  model_copy = keras.models.clone_model(model)\n",
        "  for layer in model_copy.layers:\n",
        "    layer.trainable = False \n",
        "  \n",
        "  # Generate output models of each hidden layer\n",
        "  output_models = []\n",
        "  for layer in model_copy.layers[4:-2]:\n",
        "    out_model_input = model_copy.input # [left_input, right_input]\n",
        "    if 'left' in layer.name:\n",
        "        out_model_input = out_model_input[0]\n",
        "    elif 'right' in layer.name:\n",
        "        out_model_input = out_model_input[1]\n",
        "         \n",
        "    out_model_output = keras.layers.Dense(10, activation=\"softmax\")(layer.output)\n",
        "    out_model = keras.models.Model(\n",
        "      inputs=out_model_input, outputs=out_model_output\n",
        "    )\n",
        "    output_models.append(out_model)\n",
        "\n",
        "  return output_models\n",
        "\n",
        "def show_dataset_sizes(*data):\n",
        "    for d in data:\n",
        "        print(d.shape)\n",
        "\n",
        "def data_generator_double_visual_field(x_data_left, x_data_right, y_data, batch_size):\n",
        "    while True:\n",
        "        for i in range(0, len(y_data), batch_size):\n",
        "            yield [x_data_left[i:i+batch_size], x_data_right[i:i+batch_size]], y_data[i:i+batch_size]\n",
        "\n",
        "def data_generator_single_visual_field(x_data, y_data, batch_size):\n",
        "    while True:\n",
        "        for i in range(0, len(y_data), batch_size):\n",
        "            yield x_data[i:i+batch_size], y_data[i:i+batch_size]\n",
        "        \n",
        "def is_double_visual_field_model(model):\n",
        "    return type(model.input) == list # If input is a list, it is a double visual field model\n",
        "\n",
        "def is_left_visual_field_model(model):\n",
        "    return not is_double_visual_field_model(model) and 'left' in model.input.name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KDF0o3MPTnl"
      },
      "source": [
        "Single visual field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2jFkGOJjfDk"
      },
      "outputs": [],
      "source": [
        "def display_single_visual_field_mnist_nn_execution(\n",
        "    model, x_data, y_data, input_digit, max_neurons, weight_plot_threshold\n",
        "):\n",
        "    \"\"\"\n",
        "    Receives a trained Neural Network model and and input digit, plotting the full neural network execution\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\" Determining matplotlib figure parameters \"\"\"\n",
        "\n",
        "    fig = plt.figure(\n",
        "        figsize=(12, 12)\n",
        "    )  # TODO: generate size based on max number of neurons on layer\n",
        "    ax = fig.gca()\n",
        "    ax.axis(\"off\")\n",
        "    left, right, bottom, top = 0.1, 0.9, 0.1, 0.9\n",
        "\n",
        "    \"\"\" Calculating neural network activations \"\"\"\n",
        "\n",
        "    model_activations = get_activations_single_visual_field(\n",
        "        model, input_digit, x_data, y_data\n",
        "    )\n",
        "\n",
        "    \"\"\" Determining neural network figure parameters \"\"\"\n",
        "\n",
        "    model_number_of_layers = len(model.layers)\n",
        "    layer_spacing = (right - left) / (model_number_of_layers - 1)  # Space between each layer in the plot\n",
        "    connection_opacity = 0.2\n",
        "    color_connection_opacity = 0.5\n",
        "    image_y_position = 0.5\n",
        "    current_position = Position(left, image_y_position)  # Initial position\n",
        "\n",
        "    \"\"\" Plotting layers \"\"\"\n",
        "\n",
        "    plotted_layers = []\n",
        "    for i in range(model_number_of_layers):\n",
        "        model_layer = model.layers[i]\n",
        "        layer_activations = model_activations[i]  # TODO: Can raise error if number of activations not equal to number of layers\n",
        "\n",
        "        layer = Layer(model=model_layer, activations=layer_activations)\n",
        "        plotted_layers.append(layer)  # Adding layer to plotted layers\n",
        "\n",
        "        # Depending on the type of layer, different  figures will be created to represent it\n",
        "\n",
        "        # -- Flatten layer --\n",
        "        if \"flatten\" in layer.model.name:\n",
        "            # If it is the input layer\n",
        "            if i == 0:\n",
        "                layer.position = current_position.copy()\n",
        "                ab = generate_image_annotation_box_grayscale(\n",
        "                    get_image(layer.activations),\n",
        "                    layer.position,\n",
        "                    size=calculate_image_size(layer.num_neurons),\n",
        "                )\n",
        "                ax.add_artist(ab)\n",
        "\n",
        "        #  -- Dense layer --\n",
        "        elif \"dense\" in layer.model.name:\n",
        "\n",
        "            # -- Plotting neurons of dense layer --\n",
        "            if layer.num_neurons < max_neurons:  # Plotting individual neurons\n",
        "                current_position.x += layer_spacing\n",
        "                current_position.y = top\n",
        "                layer.position = current_position.copy()\n",
        "\n",
        "                previous_layer = plotted_layers[i - 1]  # Gets previous layer\n",
        "                layer_weights = normalize_ndarray(layer.model.get_weights()[0])\n",
        "\n",
        "                neuron_spacing = (top - bottom) / layer.num_neurons  # Space between each neuron in the plot\n",
        "                layer_activations = (\n",
        "                    normalize_ndarray(layer_activations)\n",
        "                    if not layer.is_output_layer()\n",
        "                    else layer_activations\n",
        "                )  # Normalize layer activations if it is not output layer\n",
        "                for idx, neuron_activation in enumerate(layer_activations):\n",
        "                    # -- Plotting each neuron --\n",
        "                    neuron = Neuron(\n",
        "                        neuron_activation,\n",
        "                        current_position.copy(),\n",
        "                        radius=neuron_spacing / 4,\n",
        "                    )\n",
        "                    layer.neurons.append(neuron)  # Adding neuron to plotted layer\n",
        "                    neuron_circle = plt.Circle(\n",
        "                        xy=(current_position.x, current_position.y),\n",
        "                        radius=neuron.radius,\n",
        "                        color=plt.cm.viridis(neuron_activation),\n",
        "                        ec=\"k\",\n",
        "                    )\n",
        "                    ax.add_artist(neuron_circle)  # Plots neuron\n",
        "\n",
        "                    # -- Plotting connections of neurons to previous layer --\n",
        "                    if (previous_layer.num_neurons < max_neurons):  # Checks if the number of neurons on the previous layer doesn't exceed the maximum to be plotted)\n",
        "                        layer_weights_neuron = layer_weights[:, idx]\n",
        "                        for previous_neuron, connection_weight in zip(previous_layer.neurons, layer_weights_neuron):\n",
        "                            # Checks if weight is above threshold\n",
        "                            if connection_weight >= weight_plot_threshold:\n",
        "                                connection = plt.Line2D(\n",
        "                                    [\n",
        "                                        current_position.x - neuron.radius,\n",
        "                                        previous_neuron.position.x + previous_neuron.radius,\n",
        "                                    ],\n",
        "                                    [current_position.y, previous_neuron.position.y],\n",
        "                                    color=plt.cm.viridis(connection_weight),\n",
        "                                    alpha=color_connection_opacity,\n",
        "                                )\n",
        "                                ax.add_artist(connection)  # Plots connection to previous neurons\n",
        "\n",
        "                    else:  # In case it does, only a single conncetion from each neuron will be shown connecting to the previous layer\n",
        "                        previous_layer_position = Position(previous_layer.position.x, previous_layer.position.y)  # Saves position of previous layer\n",
        "                        image_offset = 0.065\n",
        "                        connection = plt.Line2D(\n",
        "                            [\n",
        "                                current_position.x - neuron.radius,\n",
        "                                previous_layer_position.x + image_offset\n",
        "                            ],\n",
        "                            [current_position.y, previous_layer_position.y],\n",
        "                            color=\"k\",\n",
        "                            alpha=connection_opacity,\n",
        "                        )\n",
        "                        ax.add_artist(connection)  # Plots connection to image\n",
        "\n",
        "                    # -- Plotting digit and activation if it is the output layer --\n",
        "                    if i == model_number_of_layers - 1:\n",
        "                        neuron_digit = get_digit_from_y_spacing(\n",
        "                            (top - current_position.y), neuron_spacing\n",
        "                        )\n",
        "                        text_offset_x = 0.001\n",
        "                        text_offset_y = 0.005\n",
        "                        text = plt.Text(\n",
        "                            current_position.x + neuron.radius + text_offset_x,\n",
        "                            current_position.y - text_offset_y,\n",
        "                            f\"{neuron_digit}: {neuron_activation:.4f}\",\n",
        "                            fontsize=8,\n",
        "                            color=\"k\",\n",
        "                        )\n",
        "                        ax.add_artist(text)  # Adds corresponding digit and activation of neuron\n",
        "\n",
        "                    # Changes the current y position to plot the next neuron\n",
        "                    current_position.y -= neuron_spacing\n",
        "\n",
        "            else:  # If the number of neurons in the layer exceeds the maximum TODO: Color connections if previous layer has few neurons\n",
        "                current_position.x += layer_spacing\n",
        "                current_position.y = image_y_position\n",
        "                layer.position = current_position.copy()\n",
        "\n",
        "                # -- Plotting layer as image --\n",
        "                ab = generate_image_annotation_box(\n",
        "                    get_image(layer.activations),\n",
        "                    layer.position,\n",
        "                    size=calculate_image_size(layer.num_neurons),\n",
        "                )\n",
        "                ax.add_artist(ab)\n",
        "\n",
        "                # -- Plotting connections of image to previous layer --\n",
        "                previous_layer = plotted_layers[i - 1]  # Gets previous layer\n",
        "                if (previous_layer.num_neurons < max_neurons):  # Checks if the number of neurons on the previous layer doesn't exceed the maximum to be plotted\n",
        "                    for previous_neuron in previous_layer.neurons:\n",
        "                        connection = plt.Line2D(\n",
        "                            [\n",
        "                                current_position.x,\n",
        "                                previous_neuron.position.x + previous_neuron.radius,\n",
        "                            ],\n",
        "                            [current_position.y, previous_neuron.position.y],\n",
        "                            color=\"k\",\n",
        "                            alpha=connection_opacity,\n",
        "                        )\n",
        "                        ax.add_artist(connection)  # Plots connection to previous neurons\n",
        "                else:  # If previous layer exceeds the maximum number of neurons plotted\n",
        "                    connection = plt.Line2D(\n",
        "                        [current_position.x, previous_layer.position.x],\n",
        "                        [current_position.y, previous_layer.position.y],\n",
        "                        color=\"k\",\n",
        "                        alpha=connection_opacity,\n",
        "                    )\n",
        "                    ax.add_artist(connection)  # Plots connection to previous neurons\n",
        "\n",
        "    fig.savefig(\"nn.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Double visual field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwa-_7o9X9XH"
      },
      "outputs": [],
      "source": [
        "def display_double_visual_field_mnist_nn_execution(\n",
        "    model,\n",
        "    max_neurons,\n",
        "    weight_plot_threshold,\n",
        "    x_data=None,\n",
        "    left_vf_digit: Tuple[int, float] = None,\n",
        "    right_vf_digit: Tuple[int, float] = None,\n",
        "    x_data_left=None,\n",
        "    x_data_right=None,\n",
        "    y_data=None,\n",
        "    input_digit=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Receives a trained Neural Network model with two visual fields and and input digit, plotting the full neural network execution.\n",
        "    Obseravtion: this code currently doesn't support Convolution or MaxPool layers and layers with too many neurons.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\" Determining matplotlib figure parameters \"\"\"\n",
        "\n",
        "    fig = plt.figure(\n",
        "        figsize=(24, 24)\n",
        "    )  # TODO: generate size based on max number of neurons on layer\n",
        "    ax = fig.gca()\n",
        "    ax.axis(\"off\")\n",
        "    top, bottom, left, right = compute_sizes(top=0.98)\n",
        "    precision = 4  # Number of digits of precision when calculating positions\n",
        "    middle = round((top + bottom) / 2, ndigits=precision)\n",
        "    middle_spacing = 0.02\n",
        "\n",
        "    \"\"\" Calculating neural network activations \"\"\"\n",
        "\n",
        "    if left_vf_digit is None:\n",
        "        model_activations = get_activations_double_visual_field(\n",
        "            model, input_digit, x_data_left, x_data_right, y_data\n",
        "        )\n",
        "    else:\n",
        "        model_activations = get_activations_double_visual_field(\n",
        "            model, x_data, left_vf_digit, right_vf_digit\n",
        "        )\n",
        "\n",
        "    \"\"\" Determining neural network figure parameters \"\"\"\n",
        "\n",
        "    model_number_of_layers = len(model.layers)\n",
        "    layer_spacing = (right - left) / (model_number_of_layers - 1)  # Space between each layer in the plot\n",
        "    connection_opacity = 0.2\n",
        "    color_connection_opacity = 0.5\n",
        "    left_vf_position = Position(left, 1.5 * middle)  # Initial position of left visual field\n",
        "    right_vf_position = Position(left, 0.5 * middle)  # Initial position of right visual field\n",
        "\n",
        "    \"\"\" Plotting layers \"\"\"\n",
        "\n",
        "    plotted_layers_left_vf = []\n",
        "    plotted_layers_right_vf = []\n",
        "    plotted_layers_concatenated = []\n",
        "    layers_reference = None\n",
        "\n",
        "    # Input layers\n",
        "\n",
        "    # Left\n",
        "    input_layer_left = Layer(model=model.layers[2], activations=model_activations[2])\n",
        "    input_layer_left.position = left_vf_position.copy()\n",
        "    ab = generate_image_annotation_box_grayscale(\n",
        "        get_image(input_layer_left.activations),\n",
        "        input_layer_left.position,\n",
        "        size=calculate_image_size(input_layer_left.num_neurons),\n",
        "    )\n",
        "    ax.add_artist(ab)\n",
        "    plotted_layers_left_vf.append(input_layer_left)\n",
        "\n",
        "    # Right\n",
        "    input_layer_right = Layer(model=model.layers[3], activations=model_activations[3])\n",
        "    input_layer_right.position = right_vf_position.copy()\n",
        "    ab = generate_image_annotation_box_grayscale(\n",
        "        get_image(input_layer_right.activations),\n",
        "        input_layer_right.position,\n",
        "        size=calculate_image_size(input_layer_right.num_neurons),\n",
        "    )\n",
        "    ax.add_artist(ab)\n",
        "    plotted_layers_right_vf.append(input_layer_right)\n",
        "\n",
        "    # Plotting the rest of the layers\n",
        "\n",
        "    # Variables used to keep track of each visual field\n",
        "    left_idx = 0\n",
        "    right_idx = 0\n",
        "    concat_idx = 0\n",
        "    concat_left_idx = 0\n",
        "    concat_right_idx = 0\n",
        "    neuron_digit = 0\n",
        "    is_concatenated = False\n",
        "    is_concatenate_layer = False\n",
        "    is_output_layer = False\n",
        "    plot_connections_left_vf = True  # Used in concatenate layer\n",
        "\n",
        "    # Plotting layers, either left vf, right vf or concatenated vf\n",
        "    for i in range(4, model_number_of_layers):\n",
        "        model_layer = model.layers[i]\n",
        "        layer_activations = model_activations[i]\n",
        "        layer = Layer(model=model_layer, activations=layer_activations)\n",
        "\n",
        "        # Determining if it is plotting left vf, right vf or concatenated vf\n",
        "        vf_top = top\n",
        "        vf_bottom = bottom\n",
        "        if \"left\" in layer.model.name:\n",
        "            layers_reference = plotted_layers_left_vf\n",
        "            left_idx += 1\n",
        "            layers_idx = left_idx\n",
        "            vf_bottom = middle + middle_spacing\n",
        "        elif \"right\" in layer.model.name:\n",
        "            layers_reference = plotted_layers_right_vf\n",
        "            right_idx += 1\n",
        "            layers_idx = right_idx\n",
        "            vf_top = middle - middle_spacing\n",
        "        elif \"concatenate\" in layer.model.name:\n",
        "            is_concatenate_layer = True\n",
        "            is_concatenated = True\n",
        "            layers_reference = plotted_layers_concatenated\n",
        "            layers_idx = concat_idx\n",
        "        elif is_concatenated:\n",
        "            concat_idx += 1\n",
        "            layers_idx = concat_idx\n",
        "        if i == model_number_of_layers - 1:\n",
        "            is_output_layer = True\n",
        "            output_offset = 0.2\n",
        "            vf_top = middle + output_offset\n",
        "            vf_bottom = middle - output_offset\n",
        "\n",
        "        # Adds current layer to plotted layers for each visual field\n",
        "        layers_reference.append(layer)\n",
        "\n",
        "        # Gets previous layer and layer weights\n",
        "        if not is_concatenate_layer:\n",
        "            layer_weights = normalize_ndarray(layer.model.get_weights()[0])  # Retruns 2d-array (num_neurons_previous_layer x num_neurons_current_layer)\n",
        "            # get_weights returns (weights, bias)\n",
        "            previous_layer = layers_reference[layers_idx - 1]\n",
        "            current_position = previous_layer.position.copy()\n",
        "\n",
        "        # Determines and saves position of current layer\n",
        "        current_position.x += layer_spacing\n",
        "        current_position.y = vf_top\n",
        "        layer.position = current_position.copy()\n",
        "\n",
        "        # Determines neuron spacing\n",
        "        neuron_spacing = (vf_top - vf_bottom) / layer.num_neurons\n",
        "        # ns_min = 0.05\n",
        "        # neuron_spacing = min(neuron_spacing, ns_min)\n",
        "\n",
        "        # Normalize layer activations if it is not output layer\n",
        "        layer_activations = (\n",
        "            normalize_ndarray(layer_activations)\n",
        "            if not is_output_layer\n",
        "            else layer_activations\n",
        "        )\n",
        "        for idx, neuron_activation in enumerate(layer_activations):\n",
        "            # -- Plotting each neuron --\n",
        "            neuron = Neuron(\n",
        "                neuron_activation, current_position.copy(), radius=neuron_spacing / 4\n",
        "            )\n",
        "            layer.neurons.append(neuron)  # Adding neuron to plotted layer\n",
        "            neuron_circle = plt.Circle(\n",
        "                xy=(current_position.x, current_position.y),\n",
        "                radius=neuron.radius,\n",
        "                color=plt.cm.viridis(neuron_activation),\n",
        "                ec=\"k\",\n",
        "            )\n",
        "            ax.add_artist(neuron_circle)  # Plots neuron\n",
        "\n",
        "            if not is_concatenate_layer:\n",
        "                # -- Plotting connections of neurons to previous layer --\n",
        "                if (previous_layer.num_neurons < max_neurons):  # Checks number of neurons on previous layer to decide if every connection will be plotted\n",
        "                    layer_weights_neuron = layer_weights[:, idx]\n",
        "                    for previous_neuron, connection_weight in zip(previous_layer.neurons, layer_weights_neuron):\n",
        "                        # Checks if weight is above threshold\n",
        "                        if connection_weight >= weight_plot_threshold:\n",
        "                            connection = plt.Line2D(\n",
        "                                [\n",
        "                                    current_position.x - neuron.radius,\n",
        "                                    previous_neuron.position.x + previous_neuron.radius,\n",
        "                                ],\n",
        "                                [current_position.y, previous_neuron.position.y],\n",
        "                                color=plt.cm.viridis(connection_weight),\n",
        "                                alpha=color_connection_opacity,\n",
        "                            )\n",
        "                            ax.add_artist(connection)  # Plots connection to previous neurons\n",
        "\n",
        "                else:  # In case it does, only a single conncetion from each neuron will be shown connecting to the previous layer\n",
        "                    image_offset = 0.032\n",
        "                    connection = plt.Line2D(\n",
        "                        [\n",
        "                            current_position.x - neuron.radius,\n",
        "                            previous_layer.position.x + image_offset,\n",
        "                        ],\n",
        "                        [current_position.y, previous_layer.position.y],\n",
        "                        color=\"k\",\n",
        "                        alpha=connection_opacity,\n",
        "                    )\n",
        "                    ax.add_artist(connection)  # Plots connection to image\n",
        "            # If it is the concatenate layer, show connection to corresponding neuron\n",
        "            else:\n",
        "                # Left\n",
        "                left_vf_layer = plotted_layers_left_vf[left_idx]\n",
        "                if concat_left_idx < left_vf_layer.num_neurons:\n",
        "                    previous_neuron = left_vf_layer.neurons[concat_left_idx]\n",
        "                    connection = plt.Line2D(\n",
        "                        [\n",
        "                            current_position.x - neuron.radius,\n",
        "                            previous_neuron.position.x + previous_neuron.radius,\n",
        "                        ],\n",
        "                        [current_position.y, previous_neuron.position.y],\n",
        "                        color=\"k\",\n",
        "                        alpha=connection_opacity,\n",
        "                    )\n",
        "                    ax.add_artist(connection)  # Plots connection to image\n",
        "                    concat_left_idx += 1\n",
        "\n",
        "                # Right\n",
        "                right_vf_layer = plotted_layers_right_vf[right_idx]\n",
        "                if (concat_right_idx < right_vf_layer.num_neurons and not plot_connections_left_vf):\n",
        "                    previous_neuron = right_vf_layer.neurons[concat_right_idx]\n",
        "                    connection = plt.Line2D(\n",
        "                        [\n",
        "                            current_position.x - neuron.radius,\n",
        "                            previous_neuron.position.x + previous_neuron.radius,\n",
        "                        ],\n",
        "                        [current_position.y, previous_neuron.position.y],\n",
        "                        color=\"k\",\n",
        "                        alpha=connection_opacity,\n",
        "                    )\n",
        "                    ax.add_artist(connection)  # Plots connection to image\n",
        "                    concat_right_idx += 1\n",
        "\n",
        "                plot_connections_left_vf = (\n",
        "                    False if concat_left_idx == left_vf_layer.num_neurons else True\n",
        "                )\n",
        "\n",
        "            # -- Plotting digit and activation if it is the output layer --\n",
        "            if is_output_layer:\n",
        "                text_offset_x = 0.001\n",
        "                text_offset_y = 0.005\n",
        "                text = plt.Text(\n",
        "                    current_position.x + neuron.radius + text_offset_x,\n",
        "                    current_position.y - text_offset_y,\n",
        "                    f\"{neuron_digit}: {neuron_activation:.4f}\",\n",
        "                    fontsize=8,\n",
        "                    color=\"k\",\n",
        "                )\n",
        "                ax.add_artist(text)  # Adds corresponding digit and activation of neuron to scene\n",
        "                neuron_digit += 1\n",
        "\n",
        "            # Changes the current y position to plot the next neuron\n",
        "            current_position.y -= neuron_spacing\n",
        "\n",
        "        if is_concatenate_layer:\n",
        "            is_concatenate_layer = False  # It will not be the concatenate layer anymore\n",
        "\n",
        "    fig.savefig(\"images/nn_dvf.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model_t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5x1u0UJWqzm",
        "outputId": "123ada85-6081-42a3-e18c-83a048c6d639"
      },
      "outputs": [],
      "source": [
        "input_left = keras.layers.Input(shape=[28,28], name=\"input_left\")\n",
        "flatten_input_left  = keras.layers.Flatten()(input_left)\n",
        "\n",
        "input_right = keras.layers.Input(shape=[28,28], name=\"input_right\")\n",
        "flatten_input_right  = keras.layers.Flatten()(input_right)\n",
        "\n",
        "hidden_layer_left1 = keras.layers.Dense(30, activation=\"relu\", name=\"dense_left1\")(flatten_input_left)\n",
        "hidden_layer_left2 = keras.layers.Dense(20, activation=\"relu\", name=\"dense_left2\")(hidden_layer_left1)\n",
        "\n",
        "hidden_layer_right1 = keras.layers.Dense(30, activation=\"relu\", name=\"dense_right1\")(flatten_input_right)\n",
        "hidden_layer_right2 = keras.layers.Dense(20, activation=\"relu\", name=\"dense_right2\")(hidden_layer_right1)\n",
        "\n",
        "concatenate_layer = keras.layers.concatenate([hidden_layer_left2, hidden_layer_right2], name=\"concatenate\")\n",
        "\n",
        "hidden_layer_concat1 = keras.layers.Dense(40, activation=\"relu\", name=\"dense_concat1\")(concatenate_layer)\n",
        "hidden_layer_concat2 = keras.layers.Dense(30, activation=\"relu\", name=\"dense_concat2\")(hidden_layer_concat1)\n",
        "\n",
        "output_layer = keras.layers.Dense(10, activation=\"softmax\")(hidden_layer_concat2)\n",
        "\n",
        "model_t1 = keras.Model(inputs=[input_left, input_right], outputs=[output_layer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training model with generator\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "training_generator = data_generator_double_visual_field(\n",
        "    x_train_left, x_train_right, y_train_final, batch_size\n",
        ")\n",
        "testing_generator = data_generator_double_visual_field(\n",
        "    x_test_left, x_test_right, y_test_final, batch_size\n",
        ")\n",
        "\n",
        "model_t1.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "history_model_t1 = model_t1.fit(\n",
        "    training_generator,\n",
        "    steps_per_epoch=len(y_train_final) // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=testing_generator,\n",
        "    validation_steps=len(y_test_final) // batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model_t1 = keras.models.load_model('models/model_t1.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display_double_visual_field_mnist_nn_execution(\n",
        "    model_t1,\n",
        "    max_neurons=300,\n",
        "    weight_plot_threshold=0.8,\n",
        "    x_data=x_test,\n",
        "    left_vf_digit=(6, 1),\n",
        "    right_vf_digit=(61, 0.5),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training out models with generator\n",
        "\n",
        "output_models = generate_output_models(model=model_t1)\n",
        "epochs = 5\n",
        "batch_size = 256\n",
        "training_generator = None\n",
        "for out_model in output_models:\n",
        "    if is_double_visual_field_model(out_model):\n",
        "        training_generator = data_generator_double_visual_field(x_train_left, x_train_right, y_train_final, batch_size)\n",
        "        testing_generator = data_generator_double_visual_field(x_test_left, x_test_right, y_test_final, batch_size)\n",
        "    else:\n",
        "        training_generator = data_generator_single_visual_field(x_train, y_train, batch_size)\n",
        "        testing_generator = data_generator_single_visual_field(x_test, y_test, batch_size)\n",
        "    \n",
        "    out_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "    out_model.fit(training_generator, steps_per_epoch=len(y_train_final) // batch_size, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "left_vf_digit = (6, 1)\n",
        "\n",
        "left_idx, left_attention = left_vf_digit\n",
        "input_data_left = np.array([x_test[left_idx]]) * left_attention\n",
        "\n",
        "right_vf_digit=(61, 0.5)\n",
        "\n",
        "right_idx, right_attention = right_vf_digit\n",
        "input_data_right = np.array([x_test[right_idx]]) * right_attention\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "axs[0].imshow(input_data_left[0], cmap=\"binary\", vmax=1)\n",
        "axs[0].set_title('Left Image')\n",
        "\n",
        "axs[1].imshow(input_data_right[0], cmap=\"binary\", vmax=1)\n",
        "axs[1].set_title('Right Image')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "def compute_digit_model_predicts(model, *data):\n",
        "    '''\n",
        "        Returns the digit the model predicts for the given input data\n",
        "\n",
        "        Input:\n",
        "        model: keras.Model: model to be used for prediction\n",
        "        *data: np.array: input data to be used for prediction, could be one or two arrays \n",
        "    \n",
        "    '''\n",
        "    activations = None\n",
        "    if len(data) == 2:\n",
        "        activations = model([data[0], data[1]])[0]\n",
        "    else:\n",
        "        activations = model(data[0])[0]\n",
        "    \n",
        "    return (np.argmax(activations), np.max(activations))\n",
        "\n",
        "def compute_digit_output_models_predict(output_models, input_data_left, input_data_right):\n",
        "    output_digits = []\n",
        "    for out_model in output_models:\n",
        "        if is_double_visual_field_model(out_model):\n",
        "            output_digits.append(compute_digit_model_predicts(out_model, input_data_left, input_data_right))\n",
        "        else:\n",
        "            if is_left_visual_field_model(out_model):\n",
        "                output_digits.append(compute_digit_model_predicts(out_model, input_data_left))\n",
        "            else:\n",
        "                output_digits.append(compute_digit_model_predicts(out_model, input_data_right))\n",
        "    \n",
        "    return output_digits\n",
        "\n",
        "output_digits = compute_digit_output_models_predict(output_models, input_data_left, input_data_right)\n",
        "print(output_digits)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
