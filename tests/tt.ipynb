{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Tuple, List, Dict, Callable\n",
    "from modules.dataset.dataset import Dataset, Data\n",
    "from modules.utils.utils import *\n",
    "from modules.metrics.metrics import *\n",
    "\n",
    "mnist_dataset = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataset.load_data()\n",
    "x_train, x_test = normalize_dataset(x_train, x_test)\n",
    "train = Data(x_train, y_train)\n",
    "test = Data(x_test, y_test)\n",
    "\n",
    "dataset = Dataset(train, test)\n",
    "dataset.build_vf_dataset(proportion_cs=0.5, \n",
    "                        proportion_left=0.5, \n",
    "                        full_attention_value=1, \n",
    "                        reduced_attention_value=0.5, \n",
    "                        ss_attention_value=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_60797\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " left_input (InputLayer)     [(None, 28, 28)]             0         []                            \n",
      "                                                                                                  \n",
      " right_input (InputLayer)    [(None, 28, 28)]             0         []                            \n",
      "                                                                                                  \n",
      " left_flatten (Flatten)      (None, 784)                  0         ['left_input[0][0]']          \n",
      "                                                                                                  \n",
      " right_flatten (Flatten)     (None, 784)                  0         ['right_input[0][0]']         \n",
      "                                                                                                  \n",
      " left_dense1 (Dense)         (None, 32)                   25120     ['left_flatten[0][0]']        \n",
      "                                                                                                  \n",
      " right_dense1 (Dense)        (None, 32)                   25120     ['right_flatten[0][0]']       \n",
      "                                                                                                  \n",
      " left_dense2 (Dense)         (None, 32)                   1056      ['left_dense1[0][0]']         \n",
      "                                                                                                  \n",
      " right_dense2 (Dense)        (None, 32)                   1056      ['right_dense1[0][0]']        \n",
      "                                                                                                  \n",
      " left_dense3 (Dense)         (None, 32)                   1056      ['left_dense2[0][0]']         \n",
      "                                                                                                  \n",
      " right_dense3 (Dense)        (None, 32)                   1056      ['right_dense2[0][0]']        \n",
      "                                                                                                  \n",
      " left_dense4 (Dense)         (None, 32)                   1056      ['left_dense3[0][0]']         \n",
      "                                                                                                  \n",
      " right_dense4 (Dense)        (None, 32)                   1056      ['right_dense3[0][0]']        \n",
      "                                                                                                  \n",
      " left_dense5 (Dense)         (None, 32)                   1056      ['left_dense4[0][0]']         \n",
      "                                                                                                  \n",
      " right_dense5 (Dense)        (None, 32)                   1056      ['right_dense4[0][0]']        \n",
      "                                                                                                  \n",
      " left_dense6 (Dense)         (None, 32)                   1056      ['left_dense5[0][0]']         \n",
      "                                                                                                  \n",
      " right_dense6 (Dense)        (None, 32)                   1056      ['right_dense5[0][0]']        \n",
      "                                                                                                  \n",
      " left_dense7 (Dense)         (None, 32)                   1056      ['left_dense6[0][0]']         \n",
      "                                                                                                  \n",
      " right_dense7 (Dense)        (None, 32)                   1056      ['right_dense6[0][0]']        \n",
      "                                                                                                  \n",
      " left_dense8 (Dense)         (None, 32)                   1056      ['left_dense7[0][0]']         \n",
      "                                                                                                  \n",
      " right_dense8 (Dense)        (None, 32)                   1056      ['right_dense7[0][0]']        \n",
      "                                                                                                  \n",
      " left_dense9 (Dense)         (None, 32)                   1056      ['left_dense8[0][0]']         \n",
      "                                                                                                  \n",
      " right_dense9 (Dense)        (None, 32)                   1056      ['right_dense8[0][0]']        \n",
      "                                                                                                  \n",
      " left_dense10 (Dense)        (None, 32)                   1056      ['left_dense9[0][0]']         \n",
      "                                                                                                  \n",
      " right_dense10 (Dense)       (None, 32)                   1056      ['right_dense9[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64)                   0         ['left_dense10[0][0]',        \n",
      "                                                                     'right_dense10[0][0]']       \n",
      "                                                                                                  \n",
      " dense1 (Dense)              (None, 32)                   2080      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense2 (Dense)              (None, 32)                   1056      ['dense1[0][0]']              \n",
      "                                                                                                  \n",
      " dense3 (Dense)              (None, 32)                   1056      ['dense2[0][0]']              \n",
      "                                                                                                  \n",
      " dense4 (Dense)              (None, 32)                   1056      ['dense3[0][0]']              \n",
      "                                                                                                  \n",
      " dense5 (Dense)              (None, 32)                   1056      ['dense4[0][0]']              \n",
      "                                                                                                  \n",
      " dense6 (Dense)              (None, 32)                   1056      ['dense5[0][0]']              \n",
      "                                                                                                  \n",
      " dense7 (Dense)              (None, 32)                   1056      ['dense6[0][0]']              \n",
      "                                                                                                  \n",
      " dense8 (Dense)              (None, 32)                   1056      ['dense7[0][0]']              \n",
      "                                                                                                  \n",
      " dense9 (Dense)              (None, 32)                   1056      ['dense8[0][0]']              \n",
      "                                                                                                  \n",
      " dense10 (Dense)             (None, 32)                   1056      ['dense9[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 10)                   330       ['dense10[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 81162 (317.04 KB)\n",
      "Trainable params: 81162 (317.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dir = '../models/model_t1_denser_50_256/'\n",
    "model_path = model_dir + 'model.keras'\n",
    "out_models_dir = model_dir + 'out_models/'\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (None, 2, 5)\n",
    "(lambda x, y, z: y * z)(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from typing import List, Tuple, Optional\n",
    "from attr import define\n",
    "from modules.utils.utils import load_obj, normalize_dataset, get_current_time_string, compute_activations, compute_digits_model_predicts\n",
    "from collections.abc import Iterable\n",
    "\n",
    "mnist_dataset = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataset.load_data()\n",
    "x_train, x_test = normalize_dataset(x_train, x_test)\n",
    "\n",
    "model = tf.keras.models.load_model('../models/MODELS_TEST_PLOTTER/model_conv.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " left_input (InputLayer)     [(None, 28, 28, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " right_input (InputLayer)    [(None, 28, 28, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " left_conv1 (Conv2D)         (None, 28, 28, 1)            10        ['left_input[0][0]']          \n",
      "                                                                                                  \n",
      " right_conv1 (Conv2D)        (None, 28, 28, 1)            10        ['right_input[0][0]']         \n",
      "                                                                                                  \n",
      " left_flatten (Flatten)      (None, 784)                  0         ['left_conv1[0][0]']          \n",
      "                                                                                                  \n",
      " right_flatten (Flatten)     (None, 784)                  0         ['right_conv1[0][0]']         \n",
      "                                                                                                  \n",
      " left_dense1 (Dense)         (None, 32)                   25120     ['left_flatten[0][0]']        \n",
      "                                                                                                  \n",
      " right_dense1 (Dense)        (None, 32)                   25120     ['right_flatten[0][0]']       \n",
      "                                                                                                  \n",
      " left_dense2 (Dense)         (None, 32)                   1056      ['left_dense1[0][0]']         \n",
      "                                                                                                  \n",
      " right_dense2 (Dense)        (None, 32)                   1056      ['right_dense1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64)                   0         ['left_dense2[0][0]',         \n",
      "                                                                     'right_dense2[0][0]']        \n",
      "                                                                                                  \n",
      " drf_dense1 (Dense)          (None, 32)                   2080      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " drf_dense2 (Dense)          (None, 32)                   1056      ['drf_dense1[0][0]']          \n",
      "                                                                                                  \n",
      " drf_dense3 (Dense)          (None, 32)                   1056      ['drf_dense2[0][0]']          \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 10)                   330       ['drf_dense3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 56894 (222.24 KB)\n",
      "Trainable params: 56894 (222.24 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_neurons = (None, 28, 28, 1)\n",
    "nn = int(np.prod([el for el in num_neurons if el is not None]))\n",
    "print(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from typing import List, Tuple, Optional, Set\n",
    "from attr import define\n",
    "from modules.utils.utils import normalize_ndarray, get_current_time_string, compute_activations, compute_digits_model_predicts\n",
    "from collections.abc import Iterable\n",
    "\n",
    "@define\n",
    "class Position:\n",
    "    \"\"\"\n",
    "    Dataclass representing a position with two coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    x: float\n",
    "    y: float\n",
    "\n",
    "    def copy(self):\n",
    "        return Position(self.x, self.y)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Position({self.x}, {self.y})\"\n",
    "\n",
    "@define\n",
    "class PlottedNeuron:\n",
    "    \"\"\"\n",
    "    Dataclass representing a neuron in the Neural Network plot\n",
    "    \"\"\"\n",
    "\n",
    "    activation: float\n",
    "    position: Position\n",
    "    radius: float\n",
    "\n",
    "class PlottedLayer():\n",
    "    \"\"\"\n",
    "    Class representing a layer in the Neural Network plot\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, original_layer: tf.keras.layers.Layer, activations: Optional[List[float]] = None, position:  Optional[Position] = None):\n",
    "        # Copying necessary attributes from original layer\n",
    "        self.name = original_layer.name\n",
    "        self.weights = original_layer.get_weights()\n",
    "        self.activations = activations\n",
    "        self.position = position if position is not None else Position(0, 0)\n",
    "        self.num_neurons = self.__compute_num_neurons(original_layer.output_shape[-1])\n",
    "        self.neurons = []\n",
    "        self.type = original_layer.__class__.__name__\n",
    "        self.is_input_layer = self.type == \"InputLayer\"\n",
    "        self.is_output_layer = not bool(original_layer._outbound_nodes)\n",
    "        self.is_concatenate_layer = self.type == \"Concatenate\"\n",
    "        self.previous_layers = self.__get_previous_layers(original_layer)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"PlottedLayer({self.name}, {self.type}, {self.num_neurons}, is_input={self.is_input_layer}, is_output={self.is_output_layer}, is_concat={self.is_concatenate_layer})\"\n",
    "    \n",
    "    def __compute_num_neurons(self, num_neurons) -> int:\n",
    "        print(f\"COMPUTE NUM NEURONS CALLED ON {self.name}\")\n",
    "        print(num_neurons)\n",
    "        if (isinstance(num_neurons, Iterable)):\n",
    "            print([el for el in num_neurons if el is not None])\n",
    "            print(int(np.prod([el for el in num_neurons if el is not None])))\n",
    "            return int(np.prod([el for el in num_neurons if el is not None]))\n",
    "        return int(num_neurons)\n",
    "    \n",
    "    def __get_previous_layers(self, layer: tf.keras.layers.Layer) -> List[tf.keras.layers.Layer]:\n",
    "        previous_layers = layer._inbound_nodes[0].inbound_layers\n",
    "        if type(previous_layers) == list:\n",
    "            return previous_layers\n",
    "        return [previous_layers]\n",
    "    \n",
    "    def get_previously_plotted_layer(self, plotted_layers: List[\"PlottedLayer\"]) -> Optional[\"PlottedLayer\"]:\n",
    "        pl_queue = self.previous_layers\n",
    "        while pl_queue:\n",
    "            pl = pl_queue.pop(0)\n",
    "            #print(pl.name, set(map(lambda plt_layer: plt_layer.name, plotted_layers)))\n",
    "            for plt_layer in plotted_layers:\n",
    "                if plt_layer.name == pl.name:\n",
    "                    return plt_layer\n",
    "            pl_previous_layers = self.__get_previous_layers(pl)\n",
    "            pl_queue.extend(pl_previous_layers)\n",
    "            \n",
    "        return None\n",
    "\n",
    "@define\n",
    "class PlottingControl:\n",
    "    \"\"\"\n",
    "    Dataclass representing control variables for plotting the Neural Network\n",
    "    \"\"\"\n",
    "\n",
    "    plotted: List[PlottedLayer] = []\n",
    "    is_left_vf: bool = False\n",
    "    has_concatenated: bool = False\n",
    "    vf_top: float = 0\n",
    "    vf_bottom: float = 0\n",
    "    SHOULD_PLOT = {\"InputLayer\", \"Dense\", \"Concatenate\", \"Conv2D\"}\n",
    "\n",
    "class NeuralNetworkPlotter:\n",
    "    def __init__(\n",
    "            self, \n",
    "            model: tf.keras.Model, \n",
    "            max_neurons: int = 300,\n",
    "            weight_threshold: float = 0.5,\n",
    "            attribute_lenses: Optional[List[tf.keras.Model]] = None,\n",
    "            num_attr_lenses_top_activations: int = 3,\n",
    "            save_plots: bool = True,\n",
    "            ) -> None:\n",
    "        \n",
    "        self.model = model\n",
    "        self.max_neurons = max_neurons\n",
    "        self.weight_threshold = weight_threshold\n",
    "        self.attribute_lenses = attribute_lenses\n",
    "        self.num_attr_lenses_top_activations = num_attr_lenses_top_activations\n",
    "        self.save_plots = save_plots\n",
    "        self.__controller = None\n",
    "\n",
    "    # Single visual field plot function\n",
    "    def plot(self, data: np.array) -> None:\n",
    "        pass\n",
    "\n",
    "    # Double visual field plot function\n",
    "    def plot(self, \n",
    "             left_vf_data: np.array, \n",
    "             right_vf_data: np.array,\n",
    "             model: Optional[tf.keras.Model] = None,\n",
    "             max_neurons: Optional[int] = None,\n",
    "             weight_threshold: Optional[float] = None,\n",
    "             attribute_lenses: Optional[List[tf.keras.Model]] = None,\n",
    "             num_attr_lenses_top_activations: Optional[int] = None,\n",
    "             save_plot: Optional[bool] = None) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        Receives a trained model with two visual fields and an input, displaying the entire neural network with its\n",
    "        activations for that input.\n",
    "\n",
    "        Observation: the attention value for each visual field is applied in the function input data\n",
    "\n",
    "        Input: \n",
    "        model: tf.keras.Model: model to be used for visualization\n",
    "        left_vf_data: np.array: left visual field data\n",
    "        right_vf_data: np.array: right visual field data\n",
    "        max_neurons: int: maximum number of neurons to be plotted in a layer (default: 300)\n",
    "        weight_threshold: float: minimum weight value to be plotted, considering normalized values between 0 and 1 (default: 0.5)\n",
    "        attribute_lenses: Optional[List[tf.keras.Model]]: list of models to be used as attribute lenses for each layer (default: None)\n",
    "        num_attr_lenses_top_activations: int: number of top digit activations displayed for each attribute lens (default: 3)\n",
    "        save_plot: bool: if the neural network plot should be saved as an image (default: True)\n",
    "\n",
    "        Output:\n",
    "        displays and saves the image in results/images/ if requested\n",
    "        \"\"\"\n",
    "        \n",
    "        # Setting default values\n",
    "        if model is None:\n",
    "            model = self.model\n",
    "        if max_neurons is None:\n",
    "            max_neurons = self.max_neurons\n",
    "        if weight_threshold is None:\n",
    "            weight_threshold = self.weight_threshold\n",
    "        if attribute_lenses is None:\n",
    "            attribute_lenses = self.attribute_lenses\n",
    "        if num_attr_lenses_top_activations is None:\n",
    "            num_attr_lenses_top_activations = self.num_attr_lenses_top_activations\n",
    "        if save_plot is None:\n",
    "            save_plot = self.save_plots\n",
    "\n",
    "        # Determining matplotlib figure parameters\n",
    "        fig = plt.figure(figsize=(24, 24))\n",
    "        ax = fig.gca()\n",
    "        ax.axis(\"off\")\n",
    "        top, bottom, left, right = self.__compute_figure_sizes(top=0.98)\n",
    "        middle = round((top + bottom) / 2, ndigits=4)\n",
    "        MIDDLE_SPACING = 0.02\n",
    "\n",
    "        # Calculating neural network activations\n",
    "        model_activations = compute_activations(model, left_vf_data, right_vf_data)\n",
    "\n",
    "        # Determining neural network figure parameters\n",
    "        CONECTION_OPACITY = 0.2\n",
    "        COLOR_CONECTION_OPACITY = 0.5\n",
    "        INITIAL_LEFT_VF_POSITION = Position(left, 1.5 * middle) \n",
    "        INITIAL_RIGHT_VF_POSITION = Position(left, 0.5 * middle)  \n",
    "        model_number_of_layers = len(model.layers)\n",
    "\n",
    "        # Setting up control structure to plot layers\n",
    "        self.__controller = PlottingControl()\n",
    "        for i, (layer, activations) in enumerate(zip(model.layers, model_activations)):\n",
    "            plotted_layer = PlottedLayer(original_layer=layer, activations=activations)\n",
    "            if plotted_layer.type not in self.__controller.SHOULD_PLOT: continue # only plots layers that should be plotted\n",
    "            # Determining layer characteristics\n",
    "            self.__controller.is_left_vf = i % 2 == 0 and not (plotted_layer.is_concatenate_layer or self.__controller.has_concatenated)\n",
    "            self.__controller.vf_top = top\n",
    "            self.__controller.vf_bottom = bottom\n",
    "            # Left VF\n",
    "            if self.__controller.is_left_vf:\n",
    "                self.__controller.vf_bottom = middle + MIDDLE_SPACING\n",
    "            # Right VF\n",
    "            elif not (plotted_layer.is_concatenate_layer or self.__controller.has_concatenated):\n",
    "                self.__controller.vf_top = middle - MIDDLE_SPACING\n",
    "            # Input\n",
    "            if plotted_layer.is_input_layer:\n",
    "                plotted_layer.position = INITIAL_LEFT_VF_POSITION if self.__controller.is_left_vf else INITIAL_RIGHT_VF_POSITION\n",
    "                ab = self.__generate_image_annotation_box(\n",
    "                            plotted_layer.activations,\n",
    "                            plotted_layer.position,\n",
    "                            cmap=\"binary\",\n",
    "                            size=self.__calculate_image_size(plotted_layer.num_neurons),\n",
    "                        )\n",
    "                ax.add_artist(ab)\n",
    "                self.__controller.plotted.append(plotted_layer)\n",
    "                continue\n",
    "            # Concatenate\n",
    "            if plotted_layer.is_concatenate_layer:\n",
    "                self.__controller.has_concatenated = True\n",
    "            # Output\n",
    "            if plotted_layer.is_output_layer:\n",
    "                output_offset = 0.2\n",
    "                self.__controller.vf_top = middle + output_offset\n",
    "                self.__controller.vf_bottom = middle - output_offset\n",
    "                        \n",
    "            # Getting previosuly plotted layer\n",
    "            layer_spacing = 0.05 if len(self.__controller.plotted) < 4 else 1.3 / (model_number_of_layers-4) # adjust layer spacing based on current layer\n",
    "            previous_layer = plotted_layer.get_previously_plotted_layer(self.__controller.plotted)\n",
    "            print(plotted_layer.name, previous_layer.name)\n",
    "            plotted_layer.position.x = previous_layer.position.x + layer_spacing\n",
    "            plotted_layer.position.y = self.__controller.vf_top\n",
    "\n",
    "            print(plotted_layer.num_neurons, max_neurons)\n",
    "            if plotted_layer.num_neurons <= max_neurons:\n",
    "                print(self.__controller.vf_top, self.__controller.vf_bottom)\n",
    "                neuron_spacing = (self.__controller.vf_top - self.__controller.vf_bottom) / plotted_layer.num_neurons\n",
    "                neuron_position = plotted_layer.position.copy()\n",
    "                layer_activations = normalize_ndarray(plotted_layer.activations) if not plotted_layer.is_output_layer else plotted_layer.activations\n",
    "                for j, neuron_activation in enumerate(layer_activations):\n",
    "                    neuron = PlottedNeuron(neuron_activation, position=neuron_position.copy(), radius=neuron_spacing/4)\n",
    "                    plotted_layer.neurons.append(neuron)\n",
    "                    neuron_circle = plt.Circle(\n",
    "                        xy=(neuron.position.x, neuron.position.y),\n",
    "                        radius=neuron.radius,\n",
    "                        color=plt.cm.viridis(neuron_activation),\n",
    "                        ec=\"k\",\n",
    "                    )\n",
    "                    ax.add_artist(neuron_circle)\n",
    "                    neuron_position.y -= neuron_spacing\n",
    "            else:\n",
    "                ab = self.__generate_image_annotation_box(\n",
    "                            plotted_layer.activations,\n",
    "                            plotted_layer.position,\n",
    "                            cmap=\"viridis\",\n",
    "                            size=self.__calculate_image_size(plotted_layer.num_neurons),\n",
    "                        )\n",
    "                ax.add_artist(ab)\n",
    "            \n",
    "            self.__controller.plotted.append(plotted_layer) # add current layer to plotted layers list\n",
    "        plt.show()\n",
    "\n",
    "    def __compute_figure_sizes(self, top: float) -> List[float]:\n",
    "        \"\"\"\n",
    "        Computes sizes of the figure based on the top percentage of the figure\n",
    "        \"\"\"\n",
    "        bottom = 1 - top\n",
    "        return top, bottom, bottom, top\n",
    "    \n",
    "    def __generate_image_annotation_box(\n",
    "        self, image: np.array, position: Position, size: int, cmap=\"binary\", border_width: int = 1, border_color: str = \"black\"\n",
    "    ) -> AnnotationBbox:\n",
    "        \"\"\"\n",
    "        Generates the AnnotationBbox of the grayscale image with a border to be positioned in the figure\n",
    "        \"\"\"\n",
    "\n",
    "        img = OffsetImage(\n",
    "            image, zoom=size, cmap=cmap, norm=plt.Normalize(vmin=0, vmax=1)\n",
    "        )\n",
    "        ab = AnnotationBbox(\n",
    "            img,\n",
    "            (position.x, position.y),\n",
    "            frameon=True,\n",
    "            pad=0,\n",
    "            bboxprops=dict(\n",
    "                edgecolor=border_color, linewidth=border_width, boxstyle=\"square,pad=0.1\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return ab\n",
    "    \n",
    "    def __get_image(self, neural_activation: np.array):\n",
    "        \"\"\"\n",
    "        Transforms 1D array into 2D array to be plotted as an image\n",
    "        \"\"\"\n",
    "        num_neurons = len(neural_activation)\n",
    "        num_rows = int(np.sqrt(num_neurons))\n",
    "        num_cols = int(np.ceil(num_neurons / num_rows))\n",
    "\n",
    "        return np.array(neural_activation).reshape(num_rows, num_cols)\n",
    "\n",
    "    def __get_digit_from_y_spacing(self, total_position_plotted: float, y_spacing: float) -> int:\n",
    "        \"\"\"\n",
    "        Returns the digit an output neuron represents based on how many neurons have been plotted\n",
    "        \"\"\"\n",
    "        return np.ceil(total_position_plotted / y_spacing)\n",
    "\n",
    "    def __calculate_image_size(self, number_neurons: int) -> float:\n",
    "        \"\"\"\n",
    "        Computes size of image based on the number of neurons\n",
    "        \"\"\"\n",
    "        # Determined in tests\n",
    "        a = -5/1536\n",
    "        b = 533/96\n",
    "        return number_neurons * a + b\n",
    "\n",
    "    def generate_output_models(self, model: Optional[tf.keras.Model] = None) -> List[tf.keras.Model]:\n",
    "        \"\"\"\n",
    "        Generates output models for each hidden layer of the model\n",
    "        \"\"\"\n",
    "        if model is None:\n",
    "            model = self.model\n",
    "        \n",
    "        # Generate not trainable copy of model\n",
    "        model_copy = tf.keras.models.clone_model(model)\n",
    "        model_weights = model.get_weights()\n",
    "        model_copy.set_weights(model_weights)\n",
    "        for layer in model_copy.layers:\n",
    "            layer.trainable = False \n",
    "        \n",
    "        # Generate output models of each hidden layer\n",
    "        output_models = []\n",
    "        for layer in model_copy.layers[4:-2]:\n",
    "            out_model_input = model_copy.input # [left_input, right_input]\n",
    "            if 'left' in layer.name:\n",
    "                out_model_input = out_model_input[0]\n",
    "            elif 'right' in layer.name:\n",
    "                out_model_input = out_model_input[1]\n",
    "                \n",
    "            out_model_output = tf.keras.layers.Dense(10, activation=\"softmax\")(layer.output)\n",
    "            out_model = tf.keras.models.Model(\n",
    "            inputs=out_model_input, outputs=out_model_output\n",
    "            )\n",
    "            output_models.append(out_model)\n",
    "\n",
    "        return output_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTE NUM NEURONS CALLED ON left_input\n",
      "(None, 28, 28, 1)\n",
      "[28, 28, 1]\n",
      "784\n",
      "COMPUTE NUM NEURONS CALLED ON right_input\n",
      "(None, 28, 28, 1)\n",
      "[28, 28, 1]\n",
      "784\n",
      "COMPUTE NUM NEURONS CALLED ON left_conv1\n",
      "1\n",
      "left_conv1 left_input\n",
      "1 300\n",
      "0.98 0.52\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "RGBA sequence should have length 3 or 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plotter \u001b[38;5;241m=\u001b[39m NeuralNetworkPlotter(model)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplotter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 237\u001b[0m, in \u001b[0;36mNeuralNetworkPlotter.plot\u001b[0;34m(self, left_vf_data, right_vf_data, model, max_neurons, weight_threshold, attribute_lenses, num_attr_lenses_top_activations, save_plot)\u001b[0m\n\u001b[1;32m    235\u001b[0m neuron \u001b[38;5;241m=\u001b[39m PlottedNeuron(neuron_activation, position\u001b[38;5;241m=\u001b[39mneuron_position\u001b[38;5;241m.\u001b[39mcopy(), radius\u001b[38;5;241m=\u001b[39mneuron_spacing\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    236\u001b[0m plotted_layer\u001b[38;5;241m.\u001b[39mneurons\u001b[38;5;241m.\u001b[39mappend(neuron)\n\u001b[0;32m--> 237\u001b[0m neuron_circle \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCircle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mneuron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneuron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviridis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneuron_activation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m ax\u001b[38;5;241m.\u001b[39madd_artist(neuron_circle)\n\u001b[1;32m    244\u001b[0m neuron_position\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m neuron_spacing\n",
      "File \u001b[0;32m~/ufrgs/ic/mnist-visual-fields/.venv-ic/lib/python3.10/site-packages/matplotlib/patches.py:1973\u001b[0m, in \u001b[0;36mCircle.__init__\u001b[0;34m(self, xy, radius, **kwargs)\u001b[0m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;129m@_docstring\u001b[39m\u001b[38;5;241m.\u001b[39mdedent_interpd\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xy, radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;124;03m    Create a true circle at center *xy* = (*x*, *y*) with given *radius*.\u001b[39;00m\n\u001b[1;32m   1965\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;124;03m    %(Patch:kwdoc)s\u001b[39;00m\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1973\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mradius \u001b[38;5;241m=\u001b[39m radius\n",
      "File \u001b[0;32m~/ufrgs/ic/mnist-visual-fields/.venv-ic/lib/python3.10/site-packages/matplotlib/patches.py:1614\u001b[0m, in \u001b[0;36mEllipse.__init__\u001b[0;34m(self, xy, width, height, angle, **kwargs)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;129m@_docstring\u001b[39m\u001b[38;5;241m.\u001b[39mdedent_interpd\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xy, width, height, \u001b[38;5;241m*\u001b[39m, angle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1596\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;124;03m    %(Patch:kwdoc)s\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1614\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_center \u001b[38;5;241m=\u001b[39m xy\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_height \u001b[38;5;241m=\u001b[39m width, height\n",
      "File \u001b[0;32m~/ufrgs/ic/mnist-visual-fields/.venv-ic/lib/python3.10/site-packages/matplotlib/patches.py:81\u001b[0m, in \u001b[0;36mPatch.__init__\u001b[0;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m edgecolor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m facecolor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m         _api\u001b[38;5;241m.\u001b[39mwarn_external(\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m property will override \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe edgecolor or facecolor properties.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_edgecolor(edgecolor)\n",
      "File \u001b[0;32m~/ufrgs/ic/mnist-visual-fields/.venv-ic/lib/python3.10/site-packages/matplotlib/patches.py:418\u001b[0m, in \u001b[0;36mPatch.set_color\u001b[0;34m(self, c)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_color\u001b[39m(\u001b[38;5;28mself\u001b[39m, c):\n\u001b[1;32m    406\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    Set both the edgecolor and the facecolor.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m        For setting the edge or face color individually.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_facecolor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_edgecolor(c)\n",
      "File \u001b[0;32m~/ufrgs/ic/mnist-visual-fields/.venv-ic/lib/python3.10/site-packages/matplotlib/patches.py:403\u001b[0m, in \u001b[0;36mPatch.set_facecolor\u001b[0;34m(self, color)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03mSet the patch face color.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03mcolor : :mpltype:`color` or None\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_facecolor \u001b[38;5;241m=\u001b[39m color\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_facecolor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ufrgs/ic/mnist-visual-fields/.venv-ic/lib/python3.10/site-packages/matplotlib/patches.py:391\u001b[0m, in \u001b[0;36mPatch._set_facecolor\u001b[0;34m(self, color)\u001b[0m\n\u001b[1;32m    389\u001b[0m     color \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch.facecolor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    390\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fill \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_facecolor \u001b[38;5;241m=\u001b[39m \u001b[43mcolors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/ufrgs/ic/mnist-visual-fields/.venv-ic/lib/python3.10/site-packages/matplotlib/colors.py:314\u001b[0m, in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    312\u001b[0m     rgba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rgba \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Suppress exception chaining of cache lookup failure.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     rgba \u001b[38;5;241m=\u001b[39m \u001b[43m_to_rgba_no_colorcycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         _colors_full_map\u001b[38;5;241m.\u001b[39mcache[c, alpha] \u001b[38;5;241m=\u001b[39m rgba\n",
      "File \u001b[0;32m~/ufrgs/ic/mnist-visual-fields/.venv-ic/lib/python3.10/site-packages/matplotlib/colors.py:400\u001b[0m, in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid RGBA argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morig_c\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(c) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA sequence should have length 3 or 4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, Real) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m c):\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Checks that don't work: `map(float, ...)`, `np.array(..., float)` and\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# `np.array(...).astype(float)` would all convert \"0.5\" to 0.5.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid RGBA argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morig_c\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: RGBA sequence should have length 3 or 4"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter = NeuralNetworkPlotter(model)\n",
    "plotter.plot(x_test[11], x_test[10] * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.node.Node at 0x7efdfd9f58d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = model.layers\n",
    "\n",
    "layers[0]._inbound_nodes[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-ic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
